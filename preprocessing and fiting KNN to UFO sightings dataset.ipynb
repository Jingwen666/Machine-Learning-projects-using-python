{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "ufo=pd.read_csv('https://assets.datacamp.com/production/repositories/1816/datasets/a5ebfe5d2ed194f2668867603b563963af4769e9/ufo_sightings_large.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# change data types of column 'seconds' and 'date'\n",
    "ufo[\"seconds\"] = ufo['seconds'].astype('float')\n",
    "ufo[\"date\"] = pd.to_datetime(ufo['date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# drop missing data using isnull() and notnull()\n",
    "\n",
    "print(ufo[[\"length_of_time\", \"state\", \"type\"]].isnull().sum())\n",
    "\n",
    "# Keep only rows where length_of_time, state, and type are not null\n",
    "ufo_no_missing = ufo[ufo[\"length_of_time\"].notnull() & \n",
    "          ufo[\"state\"].notnull() & \n",
    "          ufo[\"type\"].notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Extract minutes from lenght_of _time column,to extract data from text, we use regular expression\n",
    "def return_minutes(time_string):\n",
    "    pattern = re.compile(r\"\\d+\")\n",
    "    num = re.match(pattern, time_string)\n",
    "    if num is not None:\n",
    "        return int(num.group(0))\n",
    "    \n",
    "# Apply the extraction to the length_of_time column\n",
    "ufo[\"minutes\"] = ufo[\"length_of_time\"].apply(lambda x: return_minutes(x))\n",
    "\n",
    "print(ufo[[\"length_of_time\", \"minutes\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# identify features that need standardization\n",
    "# Check the variance of the seconds and minutes columns, we can see the seconds column has a very large variance, which will introduce too much noise in our dataset, lets nomalize it\n",
    "print(ufo[[\"seconds\", \"minutes\"]].var())\n",
    "ufo[\"seconds_log\"] = np.log(ufo[\"seconds\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Encoding categorical variables using binary and one hot encoding\n",
    "\n",
    "ufo[\"country_enc\"] = ufo[\"country\"].apply(lambda val: 1 if val == \"us\" else 0)\n",
    "print(len(ufo[\"type\"].unique()))\n",
    "type_set = pd.get_dummies(ufo[\"type\"])\n",
    "\n",
    "# Concatenate this set back to the ufo DataFrame\n",
    "ufo = pd.concat([ufo, type_set], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# apply feature engineering to the date column\n",
    "\n",
    "ufo[\"month\"] = ufo[\"date\"].apply(lambda x:x.month)\n",
    "ufo[\"year\"] = ufo[\"date\"].apply(lambda x:x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Vectorizing Text\n",
    "# Create the tfidf vectorizer object\n",
    "vec = TfidfVectorizer()\n",
    "desc_tfidf = vec.fit_transform(ufo.desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# selecting ideal dataset by dropping redundant features\n",
    "def words_to_filter(vocab, original_vocab, vector, top_n):\n",
    "    filter_list = []\n",
    "    for i in range(0, vector.shape[0]):\n",
    "        filtered = return_weights(vocab, original_vocab, vector, i, top_n)\n",
    "        filter_list.extend(filtered)\n",
    "    return set(filter_list)\n",
    "print(ufo[[\"seconds\", \"seconds_log\", \"minutes\"]].corr())\n",
    "to_drop = [\"city\", \"country\", \"date\", \"desc\", \"lat\", \"length_of_time\", \"long\", \"minutes\", \"recorded\", \"seconds\", \"state\"]\n",
    "ufo_dropped = ufo.drop(to_drop, axis=1)\n",
    "filtered_words = words_to_filter(vocab, vec.vocabulary_, desc_tfidf, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# After preprocessing, we build a k-nearest neighbor model to predict which country the UFO sighting took place in, we have a imbalance dataset, therefore we will use stratify = y \n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, stratify=y)\n",
    "\n",
    "# Fit knn to the training sets\n",
    "knn.fit(train_X, train_y)\n",
    "\n",
    "# Print the score of knn on the test sets\n",
    "print(knn.score(test_X, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}